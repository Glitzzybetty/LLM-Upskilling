{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8741980-f779-4cc7-95ca-7b302264bd5c",
   "metadata": {},
   "source": [
    "### Project: Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07fa5656-b0c5-4f6f-96b6-469f76b72541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04389c4f-1ade-4373-ba69-e12304bbc732",
   "metadata": {},
   "source": [
    "## A) Basic Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c570e0-0edc-4736-a649-6f4d994ac6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0661119-3601-4714-a089-23955c52c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Mojo is a new programming language that bridges the gap between research and production by combining the best of Python syntax with systems \\\n",
    "programming and metaprogramming. With Mojo, you can write portable code that’s faster than C and seamlessly inter-op with the Python ecosystem.\n",
    "Mojo is designed to solve a variety of AI development challenges that no other language can, because Mojo is the first programming language \\\n",
    "built from the ground-up with MLIR (a compiler infrastructure that’s ideal for heterogeneous hardware, from CPUs and GPUs, to various AI ASICs). \\\n",
    "We also designed Mojo as a superset of the Python because we love Python and its community, but we couldn’t realistically enhance Python to do all \\\n",
    "the things we wanted.\n",
    "What we wanted was an innovative and scalable programming model that could target accelerators and other heterogeneous systems that are pervasive \\\n",
    "in the AI field. This meant a programming language with powerful compile-time metaprogramming, integration of adaptive compilation techniques, caching \\\n",
    "throughout the compilation flow, and other features that are not supported by existing languages.\n",
    "And although accelerators are important, one of the most prevalent and sometimes overlooked “accelerators” is the host CPU. \\\n",
    "Nowadays, CPUs have lots of tensor-core-like accelerator blocks and other AI acceleration units, but they also serve as the “fallback” \\\n",
    "for operations that specialized accelerators don’t handle, such as data loading, pre- and post-processing, and integrations with foreign systems. \\\n",
    "So it was clear that we couldn’t lift AI with just an “accelerator language” that worked with only specific processors.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=' You are an expert copywriter with expertize in summarizing documents'),\n",
    "    HumanMessage(content=f'Please provide a short and concise summary of the following text:\\n TEXT:{text}')\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f7a874-447e-44c7-bc00-6cedec70b644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd179c27-3dd4-46e9-ab8c-f45b0d549681",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_output = llm(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f44d842-d7e2-442c-b84e-9cb242a3a226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mojo is a new programming language that combines Python syntax with systems programming and metaprogramming. It aims to bridge the gap between research and production by allowing developers to write portable code that is faster than C and seamlessly integrates with the Python ecosystem. Mojo is designed to solve AI development challenges by utilizing MLIR, a compiler infrastructure ideal for heterogeneous hardware. It offers powerful compile-time metaprogramming, adaptive compilation techniques, caching, and other features not found in existing languages. Additionally, Mojo recognizes the importance of CPUs as accelerators and provides support for operations that specialized accelerators may not handle.\n"
     ]
    }
   ],
   "source": [
    "print(summary_output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e450019-2915-422d-817b-91080eadc56e",
   "metadata": {},
   "source": [
    "### Summarising Using Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b881df-3e6f-469e-84c5-e5866f7300f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bf3468f-a90e-4cf5-b230-07f07f070180",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''\n",
    "Write a concise and short summary of the following text:\n",
    "TEXT: `{text}`\n",
    "Translate the summary to  {language}.\n",
    "'''\n",
    "\n",
    "promp = PromptTemplate(\n",
    "    input_variables=['text', 'language'],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a96f821c-e73c-4cdd-9a2e-74492e8458b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(promp.format(text=text, language='English'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e971751-2e5d-4891-aea6-c13c4fc1cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=promp)\n",
    "summary = chain.run({'text' :text, 'language' : 'english' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "899af47d-0709-4306-83af-cf4353d17bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mojo is a new programming language that combines the best features of Python with systems programming and metaprogramming. It is designed to solve AI development challenges and is built with MLIR, making it ideal for heterogeneous hardware. Mojo is a superset of Python and offers powerful compile-time metaprogramming and other features not found in existing languages. It can target accelerators and other heterogeneous systems, including the host CPU, which is often overlooked but plays a crucial role in AI operations.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173db6c0-f8aa-4d88-9b77-d96b7b549a33",
   "metadata": {},
   "source": [
    "### Summarizing Using SuffDocumentChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8b2c770-c259-4c19-9088-d21dde7eb56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI \n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dca2ad4-3f67-4076-9ac5-5a32eb9727c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('files/sj.txt') as f:\n",
    "    text = f.read()\n",
    "    #text\n",
    "docs = [Document(page_content=text)]  # you can split document if you want\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdf0d3ae-fae7-4054-a713-38be6518515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template='''Write the concise summary of the following text.\n",
    "TEXT: `{text}`\n",
    "'''\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['text'],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "956c74c2-f52b-43de-966d-c9b9cc28dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type = 'stuff',\n",
    "    prompt=prompt,\n",
    "    verbose = False\n",
    ")\n",
    "output_summary = chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b591fdc7-848a-4aad-b5bc-9632e8e6da7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steve Jobs, CEO of Apple Computer and Pixar Animation Studios, delivered a commencement address in 2005 where he shared his personal story about facing death and emphasized the importance of following one's passion and intuition. He encouraged the graduates to not waste their limited time living someone else's life and to have the courage to pursue their own dreams. He concluded with the message to \"Stay Hungry. Stay Foolish.\"\n"
     ]
    }
   ],
   "source": [
    "print(output_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f757d1-013b-4fd5-8d9f-5bf141670293",
   "metadata": {},
   "source": [
    "### Summarizing Large Documents Using map_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2af613c5-569f-41bb-b729-d9a6457cc5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI \n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53e976f-5916-4306-9f6f-d5a55a8f1cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('files/sj.txt') as f:\n",
    "    text = f.read()\n",
    "    #text\n",
    "docs = [Document(page_content=text)]  # you can split document if you want\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de3d20b7-edc1-4556-a238-a944231aa97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1204"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8faedbb-45f1-49be-a961-6107e8cdc3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=50)\n",
    "chunks = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dbf9ead-64eb-4592-9a6b-5fc3a15c7bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1804d973-7d0a-4964-b880-7ad47d948394",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain =  load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type='map_reduce',\n",
    "    verbose = False\n",
    ")\n",
    "output_summary = chain.run(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5512f0e-1380-475c-bfa7-227fd2135fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steve Jobs, in his 2005 commencement address, discussed the significance of living each day to the fullest and following one's passion. He revealed his own battle with pancreatic cancer and emphasized the desire to make the most of life. Jobs also encouraged the audience to embrace change, live their own lives, and stay hungry and foolish.\n"
     ]
    }
   ],
   "source": [
    "print(output_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a1802f7-1ed9-46bd-bc71-16a3c5aadf85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.llm_chain.prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "745571ea-ea84-4205-b104-e7610aa9c7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.combine_document_chain.llm_chain.prompt.template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ede050-9910-42aa-a964-d186e940236d",
   "metadata": {},
   "source": [
    "### MapReduce with Custom Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42b4647f-5cab-4524-bd7c-1404f74320c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_prompt='''\n",
    "Write a short and concise summary of the following:\n",
    "Text: `{text}`\n",
    "CONCISE SUMMARY:\n",
    "'''\n",
    "\n",
    "map_prompt_template = PromptTemplate(\n",
    "    input_variables=['text'],\n",
    "    template=map_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc832f24-a008-4f08-b968-65ab1093588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_prompt='''\n",
    "Write a concise summary of the following text that covers the key points.\n",
    "Add a title to the summary.\n",
    "Start your summary with an INTRODUCTION PARAGRAPH that gives an overview of the topic FOLLOWED by BULLET POINTS if possible AND end the summary with a CONCLUSION PHRASE.\n",
    "Text: `{text}`\n",
    "'''\n",
    "combine_prompt_template = PromptTemplate(template=combine_prompt, input_variables=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9391de46-ef34-4acc-ad0b-af585118bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type='map_reduce',\n",
    "    map_prompt=map_prompt_template,\n",
    "    verbose=False #set to true to see intermediate steps\n",
    ")\n",
    "output = summary_chain.run(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29a00166-9a1f-4710-a651-7c136a7a8345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steve Jobs delivered a commencement address in 2005 where he discussed the importance of finding one's passion, living each day to the fullest, and embracing mortality. He shared his personal experience with pancreatic cancer and emphasized the need to prioritize what truly matters. The speech encourages individuals to live authentically and follow their own desires, not being influenced by others. Jobs also references The Whole Earth Catalog and its message of staying hungry and foolish as a wish for the graduating audience.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9527e037-7e3e-4d4f-a777-beeea726a233",
   "metadata": {},
   "source": [
    "### Summarizing Using Refine Combined Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820d0bf3-e3d0-49e9-8dec-d32c1adb27cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install unstructured -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5459c6-6853-47be-8e35-c90a9b791119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1a30b6-2124-4339-af53-1f263101f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install  pikepdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e204771a-3d3b-4850-a6ac-a04775052035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI \n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbcedede-52bd-490d-a22c-4c2112f45269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "712f9500-b520-4a2c-a670-dea416895082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loader = UnstructuredPDFLoader('files/attention_is_all_you_need.pdf', mode=\"elements\", strategy=\"fast\",)\n",
    "loader = PyPDFLoader('files/attention_is_all_you_need.pdf')\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b88ec0c-ebe2-4df2-a20a-8cbc18aa5e32",
   "metadata": {},
   "source": [
    "$ cat test-pdf-loader.py \n",
    "from datetime import datetime\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "# warmup so initial unstructured library-loading not included in timed results\n",
    "loader = UnstructuredPDFLoader(\n",
    "    \"/opt/home/r/unstructured/example-docs/layout-parser-paper.pdf\", mode=\"elements\", strategy=\"fast\",\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "for strategy in (\"fast\", \"hi_res\"):\n",
    "    d1 = datetime.now()\n",
    "    loader = UnstructuredPDFLoader(\n",
    "        \"/opt/home/r/unstructured/example-docs/layout-parser-paper.pdf\", mode=\"elements\", strategy=strategy,\n",
    "    )\n",
    "    docs = loader.load()\n",
    "    d2 = datetime.now()\n",
    "    print(f\"time elapsed {strategy:14}: {(d2-d1).total_seconds():.3} seconds\")\n",
    "    print(f\"length of content extracted: {len(''.join([doc.page_content for doc in docs]))}\")\n",
    "\n",
    "\n",
    "$ python test-pdf-loader.py \n",
    "time elapsed fast          : 0.905 seconds\n",
    "length of content extracted: 42359\n",
    "time elapsed hi_res        : 33.8 seconds\n",
    "length of content extracted: 44934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2927161a-9c5b-4cfe-9799-dd17cc59e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84990a43-8013-4096-aa74-6bcf2fc679ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "417eb12c-626e-4667-947a-15829cc20282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc135293-7674-4fea-a8a5-051700c993ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 10162\n",
      "Embedding Cost in USD: 0.004065\n"
     ]
    }
   ],
   "source": [
    "def print_embedding_cost(texts):\n",
    "    import tiktoken\n",
    "    enc= tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    print(f'Total Tokens: {total_tokens}')\n",
    "    print(f'Embedding Cost in USD: {total_tokens/1000*0.0004:.6f}')\n",
    "\n",
    "print_embedding_cost(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a607ffe5-07fe-4cab-9566-8472d6a44b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain =  load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type='refine',\n",
    "    verbose = False\n",
    ")\n",
    "output_summary = chain.run(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e605a56-eb5b-4339-9996-d6879f6d720c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A majority of American governments have passed new laws since 2009 to make the registration or voting process more difficult. This is illustrated in Figure 3, which shows the attention mechanism in layer 5 of 6. The attention heads in the encoder self-attention focus on the distant dependency of the verb 'making', completing the phrase 'making...more difficult'. The new context provided does not add any relevant information to the original summary. Therefore, the original summary remains unchanged.\n"
     ]
    }
   ],
   "source": [
    "print(output_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609d18c2-9e90-4044-9dd4-65096f06dd2b",
   "metadata": {},
   "source": [
    "### Refine with Custom Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b227eb80-6a4d-407e-8722-72b4605bb33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''\n",
    "Write a concise and short summary of the following extracting the key information:\n",
    "Text: `{text}`\n",
    "CONCISE SUMMARY:'''\n",
    "initial_prompt = PromptTemplate(template=prompt_template, input_variables=['text'])\n",
    "\n",
    "refine_template = '''\n",
    "    Your job is to produce a final summary.\n",
    "    I have provided an existing summary up to a certain point: {existing_answer}.\n",
    "    Please refine the existing summary with some mor context below.\n",
    "    ----------\n",
    "    {text}\n",
    "    ----------\n",
    "    Start the final summary with an INTRODUCTION PARAGRAPH that gives an overview of the topic FOLLOWED by BULLET POINTS if possible AND end the summary with a CONCLUSION PHRASE\n",
    "'''\n",
    "refine_prompt = PromptTemplate(\n",
    "    template=refine_template, \n",
    "    input_variables=['existing_answer', 'text']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "308ce856-eee7-4971-9ed5-12a7c790c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain =  load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type='refine',\n",
    "    question_prompt=initial_prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    "    return_intermediate_steps = False\n",
    ")\n",
    "output_summary = chain.run(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52618a7e-21ca-4a5a-9521-5f0308d7d0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Transformer is a groundbreaking network architecture that relies solely on attention mechanisms for sequence transduction tasks. It addresses the limitations of recurrent neural networks and achieves state-of-the-art results in machine translation and other tasks. The model consists of stacked self-attention and fully connected layers, making it the first transduction model to rely solely on self-attention. The paper introduces Scaled Dot-Product Attention and Multi-Head Attention, which further enhance the performance of the Transformer. The potential benefits of restricting self-attention to consider only a neighborhood of the input sequence and the possibility of self-attention yielding more interpretable models are discussed. The paper provides insights into the training regime for the models, including details about the training data, batching, hardware, schedule, optimizer, and regularization techniques. The Transformer achieves better BLEU scores than previous state-of-the-art models on translation tasks at a fraction of the training cost. It also performs well on English constituency parsing, outperforming all previously reported models except for the Recurrent Neural Network Grammar. In conclusion, the Transformer presents a novel approach to sequence transduction tasks by leveraging attention mechanisms. It achieves impressive results in various tasks and demonstrates the potential of self-attention in sequence modeling. The introduction of Scaled Dot-Product Attention and Multi-Head Attention further enhances the performance of the model. The paper provides valuable insights into the architecture and training of the Transformer, making it a significant advancement in the field of sequence transduction.\n"
     ]
    }
   ],
   "source": [
    "print(output_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c135a75f-e0b0-4b6a-b587-5c43d653e862",
   "metadata": {},
   "source": [
    "### Summarizing Using LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf48cf16-d2d1-4453-a41d-e1436a62a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11ed97b4-4bf9-43ca-8e6d-b6a43853f564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f82f0ea-9797-44cf-ba51-cd69b8d67841",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')\n",
    "wikipedia = WikipediaAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad57e0d9-e092-4f47-9d22-55b954621b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name='Wikipedia',\n",
    "        func=wikipedia.run,\n",
    "        description='Useful for when you nee to get information from wikipedia about a topic'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "878f1d94-b257-494d-aa0b-1c9f64ba211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = initialize_agent(tools, llm, agent='zero-shot-react-description', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "955cecbd-56a6-493d-8810-358e943fd3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should look up George Washington on Wikipedia to get a short summary of his life and accomplishments.\n",
      "Action: Wikipedia\n",
      "Action Input: George Washington\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: George Washington\n",
      "Summary: George Washington (February 22, 1732 – December 14, 1799) was an American Founding Father, military officer, and statesman who served as the first president of the United States from 1789 to 1797. Appointed by the Second Continental Congress as commander of the Continental Army in June 1775, Washington led Patriot forces to victory in the American Revolutionary War and then served as president of the Constitutional Convention in 1787, which drafted and ratified the Constitution of the United States and established the American federal government. Washington has thus been called the \"Father of his Country\".\n",
      "Washington's first public office, from 1749 to 1750, was as surveyor of Culpeper County in the Colony of Virginia. He subsequently received military training and was assigned command of the Virginia Regiment during the French and Indian War. He was later elected to the Virginia House of Burgesses and was named a delegate to the Continental Congress in Philadelphia, which appointed him Commander-in-Chief of the Continental Army. Washington led American forces to a decisive victory over the British in the Revolutionary War, leading the British to sign the Treaty of Paris, which acknowledged the sovereignty and independence of the United States. He resigned his commission in 1783 after the conclusion of the Revolutionary War.\n",
      "Washington played an indispensable role in adopting and ratifying the Constitution, which replaced the Articles of Confederation in 1789. He was then twice elected president by the Electoral College unanimously. As the first U.S. president, Washington implemented a strong, well-financed national government while remaining impartial in a fierce rivalry that emerged between cabinet members Thomas Jefferson and Alexander Hamilton. During the French Revolution, he proclaimed a policy of neutrality while additionally sanctioning the Jay Treaty. He set enduring precedents for the office of president, including republicanism, a peaceful transfer of power, use of the title \"Mr. President\", and the two-term tradition. His 1796 farewell address became a preeminent statement on republicanism in which he wrote about the importance of national unity and the dangers that regionalism, partisanship, and foreign influence pose to it. Washington's image is an icon of American culture. He has been memorialized by monuments, a federal holiday, various media depictions, geographical locations including the national capital, the State of Washington, stamps, and currency. In 1976, Washington was posthumously promoted to the rank of General of the Armies, the highest rank in the U.S. Army. \n",
      "Washington consistently ranks in both popular and scholarly polls as one of the greatest presidents in American history.\n",
      "\n",
      "Page: George Washington Carver\n",
      "Summary: George Washington Carver (c. 1864 – January 5, 1943) was an American agricultural scientist and inventor who promoted alternative crops to cotton and methods to prevent soil depletion. He was one of the most prominent black scientists of the early 20th century.\n",
      "While a professor at Tuskegee Institute, Carver developed techniques to improve types of soils depleted by repeated plantings of cotton. He wanted poor farmers to grow other crops, such as peanuts and sweet potatoes, as a source of their own food and to improve their quality of life. The most popular of his 44 practical bulletins for farmers contained 105 food recipes using peanuts. Although he spent years developing and promoting numerous products made from peanuts, none became commercially successful.Apart from his work to improve the lives of farmers, Carver was also a leader in promoting environmentalism. He received numerous honors for his work, including the Spingarn Medal of the NAACP. In an era of high racial polarization, his fame reached beyond the black community. He was widely recognized and praised in the white community for his many achievements and talents. In 1941, Time magazine \u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: George Washington (February 22, 1732 – December 14, 1799) was an American Founding Father, military officer, and statesman who served as the first president of the United States from 1789 to 1797. He played a crucial role in the American Revolutionary War, led the drafting and ratification of the Constitution, and set important precedents for the presidency. He is widely regarded as one of the greatest presidents in American history.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = agent_executor.run('Can you please provide a short summary of George Washington?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0250aab7-a446-44f1-a075-02f506b308e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington (February 22, 1732 – December 14, 1799) was an American Founding Father, military officer, and statesman who served as the first president of the United States from 1789 to 1797. He played a crucial role in the American Revolutionary War, led the drafting and ratification of the Constitution, and set important precedents for the presidency. He is widely regarded as one of the greatest presidents in American history.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d07e1-f8ae-491f-87ce-b8b7222542a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
